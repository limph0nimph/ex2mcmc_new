{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a01d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import tkinter\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pyro\n",
    "from samplers import mala, i_sir, ex2_mcmc\n",
    "\n",
    "from cifar10_experiments.models import Generator, Discriminator\n",
    "\n",
    "from sampling_utils.adaptive_mc import CISIR, Ex2MCMC, FlowMCMC\n",
    "from sampling_utils.adaptive_sir_loss import MixKLLoss\n",
    "from sampling_utils.distributions import (\n",
    "    Banana,\n",
    "    CauchyMixture,\n",
    "    Distribution,\n",
    "    Funnel,\n",
    "    HalfBanana,\n",
    "    IndependentNormal,\n",
    ")\n",
    "from sampling_utils.ebm_sampling import MALA\n",
    "from sampling_utils.flows import RNVP\n",
    "from sampling_utils.metrics import ESS, acl_spectrum\n",
    "from sampling_utils.total_variation import (\n",
    "    average_total_variation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c218c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "lat_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2472035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cifar10 = Generator(lat_size)\n",
    "gen_cifar10.to(device)\n",
    "\n",
    "discr_cifar10 = Discriminator()\n",
    "discr_cifar10.to(device)\n",
    "\n",
    "prior_cifar10 = torch.distributions.MultivariateNormal(torch.zeros(lat_size).to(device), torch.eye(lat_size).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f58bf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cifar10.load_state_dict(torch.load('./weights/generator.pkl', map_location='cpu'))\n",
    "discr_cifar10.load_state_dict(torch.load('./weights/discriminator.pkl', map_location='cpu'))\n",
    "gen_cifar10.eval()\n",
    "discr_cifar10.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49b1e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy_wgan(z):\n",
    "    return (-0.1*discr_cifar10(gen_cifar10(z)).squeeze() - prior_cifar10.log_prob(z).squeeze())\n",
    "\n",
    "def log_target_dens(x):\n",
    "    \"\"\"\n",
    "    returns the value of a target density - mixture of the 3 gaussians \n",
    "    \"\"\"\n",
    "    x = torch.FloatTensor(x).to(device)\n",
    "    return -get_energy_wgan(x).detach().cpu().numpy()\n",
    "\n",
    "def grad_log_target_dens(x):\n",
    "    \"\"\"\n",
    "    returns the gradient of log-density \n",
    "    \"\"\"\n",
    "    x = torch.FloatTensor(x).to(device)\n",
    "    x.requires_grad_(True)\n",
    "    external_grad = torch.ones(x.shape[0])\n",
    "    (-get_energy_wgan(x)).backward(gradient=external_grad)\n",
    "    return x.grad.data.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aaffcf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-292.15216, -312.44003], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_target_dens(np.random.randn(2, lat_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62db5fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_log_target_dens(np.random.randn(2, lat_size)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af669620",
   "metadata": {},
   "source": [
    "### Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b91698b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class distr:\n",
    "    \"\"\"\n",
    "    Base class for a custom target distribution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, beta = 1.0):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def log_prob(self, z):\n",
    "        \"\"\"\n",
    "        The method returns target logdensity, estimated at point z\n",
    "        Input:\n",
    "        z - datapoint\n",
    "        Output:\n",
    "        log_density: log p(z)\n",
    "        \"\"\"\n",
    "        # You should define the class for your custom distribution\n",
    "        return -get_energy_wgan(z)\n",
    "\n",
    "    def energy(self, z):\n",
    "        \"\"\"\n",
    "        The method returns target logdensity, estimated at point z\n",
    "        Input:\n",
    "        z - datapoint\n",
    "        Output:\n",
    "        energy = -log p(z)\n",
    "        \"\"\"\n",
    "        # You should define the class for your custom distribution\n",
    "        return -get_energy_wgan(z)\n",
    "\n",
    "    def __call__(self, z):\n",
    "        return self.log_prob(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763be29a",
   "metadata": {},
   "source": [
    "### Flex2MCMC parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ef6615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_flex = {\n",
    "      \"N\": 5,\n",
    "      \"grad_step\": 0.2,\n",
    "      \"adapt_stepsize\": False,\n",
    "      \"corr_coef\": 0.0,\n",
    "      \"bernoulli_prob_corr\": 0.0,\n",
    "      \"mala_steps\": 0,\n",
    "    \"flow\": {\n",
    "      \"num_flows\": 5, # number of normalizing layers \n",
    "      \"lr\": 1e-3, # learning rate \n",
    "      \"batch_size\": 5,\n",
    "      \"n_steps\": 100,\n",
    "    }\n",
    "}\n",
    "\n",
    "beta = 1.0\n",
    "scale_proposal = 1.0\n",
    "\n",
    "target = distr(beta)\n",
    "\n",
    "loc_proposal = torch.zeros(lat_size).to(device)\n",
    "scale_proposal = scale_proposal * torch.ones(lat_size).to(device)\n",
    "proposal = IndependentNormal(\n",
    "    dim=lat_size,\n",
    "    loc=loc_proposal,\n",
    "    scale=scale_proposal,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 10/100 [00:10<01:30,  1.00s/it]"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(42)\n",
    "mcmc = Ex2MCMC(**params_flex, dim=lat_size)\n",
    "verbose = mcmc.verbose\n",
    "mcmc.verbose = False\n",
    "flow = RNVP(params_flex[\"flow\"][\"num_flows\"], dim=lat_size)\n",
    "flow_mcmc = FlowMCMC(\n",
    "    target,\n",
    "    proposal,\n",
    "    flow,\n",
    "    mcmc,\n",
    "    batch_size=params_flex[\"flow\"][\"batch_size\"],\n",
    "    lr=params_flex[\"flow\"][\"lr\"],\n",
    ")\n",
    "flow.train()\n",
    "out_samples, nll = flow_mcmc.train(\n",
    "    n_steps=params_flex[\"flow\"][\"n_steps\"],\n",
    ")\n",
    "assert not torch.isnan(\n",
    "    next(flow.parameters())[0, 0],\n",
    ").item()\n",
    "\n",
    "flow.eval()\n",
    "mcmc.flow = flow\n",
    "mcmc.verbose = verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf315a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample from a normalizing flow\n",
    "n_steps_flex2 = 1000\n",
    "pyro.set_rng_seed(42)\n",
    "start = proposal.sample((batch_size,))\n",
    "mcmc.N = 20\n",
    "mcmc.mala_steps = 0\n",
    "mcmc.grad_step = 0.1\n",
    "# s = time.time()\n",
    "out = mcmc(start, target, proposal, n_steps = n_steps_flex2)\n",
    "if isinstance(out, tuple):\n",
    "    sample = out[0]\n",
    "else:\n",
    "    sample = out\n",
    "sample = np.array(\n",
    "    [_.detach().numpy() for _ in sample],\n",
    ").reshape(-1, batch_size, dim)\n",
    "sample_flex2_new = sample\n",
    "#resample with 0 mala steps\n",
    "mcmc.mala_steps = 50\n",
    "out_new = mcmc(start, target, proposal, n_steps = n_steps_flex2)[0]\n",
    "out_new = np.array(\n",
    "    [_.detach().numpy() for _ in out_new],\n",
    ").reshape(-1, batch_size, dim)\n",
    "sample_flex2_final = out_new\n",
    "print(sample_flex2_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77539c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
